---
title: "3.3 Alertrules and alerts"
weight: 2
sectionnumber: 3
---

{{% alert title="Note" color="primary" %}}

For doing the alerting lab it's useful to have a "real" application so that alerts can be provoked. The training app installed in the previous lab provides a sample app, you can start it as follows:

```bash
cd ~/training-app
./prometheus-training-app sampleapp &
```

Also, the target must be registered in Prometheus (don't forget to reload or restart Prometheus):

```yaml
  - job_name: 'sample-app'
    static_configs:
    - targets: ['localhost:8080']
```

{{% /alert %}}

### Task 1

* Define an alert rule which sends an alert when a target is down
* Wait time until the alarm should be sent is 2 minutes
* Add a label `team` with the value `team-a`
* Add an annotation `summary` with information about which instance and job is down

### Task 2

* Kill or stop the sample application
* What do you observe in Prometheus UI or in Alertmanager UI?

### Task 3

* Who is finally notified? Check the webook app.

## Solutions

{{% details title="Task 1" %}}

Create a new file `alertrule.yml` and add the following snippet:

```yaml
groups:
- name: basic
  rules:
  - alert: Up
    expr: up == 0
    for: 2m
    labels:
      team: team-b
    annotations:
      summary: Instance {{ $labels.instance }} of job {{ $labels.job }} is down
```

The value in field `for` is the wait time until the active alert gets in state `FIRING`. Before the alert is `PENDING` and not yet set to Alertmanager.

The alert is instrumented with the labels from the metric (e.g. `job`and `instance`). Additional labels can be defined in the rule. Labels can be used in Alertmanager for the routing.

With annotations additional human readable information can be attached to the alert.

In `prometheus.yml` add the rule file at `rule_files` section and restart or reload Prometheus.

```yaml
  rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"
  - alertrule.yml
```
{{% /details %}}

{{% details title="Task 2" %}}

* In the Prometheus UI there is an [alert console](http://localhost:9090/alerts) which shows you information about inactive and active alerts.
* As soon as an alert is in state `FIRING` the alert is sent to Alertmanager. You should see the alert in its [webinterface](http://localhost:9093/).

{{% /details %}}

{{% details title="Task 3" %}}

Receivers `receiver-a` and `receiver-b` should be notified in this case, as `continue: true` was used in routing blocks.

{{% /details %}}
