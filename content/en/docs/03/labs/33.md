---
title: "3.3 Tasks: Alertrules and alerts"
weight: 2
sectionnumber: 3
---

{{% alert title="Note" color="primary" %}}

For doing the alerting lab it's useful to have a "real" application so that alerts can be provoked. The training app installed in the previous lab provides a sample app; you can start it as follows:

```bash
cd ~/training-app
./prometheus-training-app sampleapp &
```

The example app exposes metrics at `http://localhost:8080/metrics`

Also, the target must be registered in Prometheus (don't forget to reload or restart Prometheus):

```yaml
  - job_name: 'sample-app'
    static_configs:
    - targets: ['localhost:8080']
```

{{% /alert %}}

### Task 1

* Define an alert rule which sends an alert when a target is down
* The wait time until the alarm should be sent is 2 minutes
* Add a label `team` with the value `team-b`
* Add an annotation `summary` with information about which instance and job is down

### Task 2

* Kill or stop the sample application
* Verify that the sample app no longer exposes metrics
* What do you observe in Prometheus UI or in Alertmanager UI?

### Task 3

* Who is finally notified?

## Solutions

{{% details title="Task 1" %}}

Create a new file `alertrule.yml` for Prometheus and add the following snippet:

```yaml
groups:
- name: basic
  rules:
  - alert: Up
    expr: up == 0
    for: 2m
    labels:
      team: team-b
    annotations:
      summary: Instance {{ $labels.instance }} of job {{ $labels.job }} is down
```

The value in field `for` is the wait time until the active alert gets in state `FIRING`. Before that, the alert is `PENDING` and not yet sent to Alertmanager.

The alert is instrumented with the labels from the metric (e.g. `job`and `instance`). Additional labels can be defined in the rule. Labels can be used in Alertmanager for the routing.

With annotations, additional human-readable information can be attached to the alert.

In `prometheus.yml`, add the rule file at `rule_files` section and restart or reload Prometheus.

```yaml
  rule_files:
  ...
  - "alertrule.yml"
```
{{% /details %}}

{{% details title="Task 2" %}}

* Kill the example app and make sure it will no longer exposes metrics

```bash
killall prometheus-training-app
curl http://localhost:8080/metrics
```

```
curl: (7) Failed connect to localhost:8080; Connection refused
```

* In the Prometheus web UI there is an **Alerts** [menu item](http://localhost:9090/alerts) which shows you information about inactive and active alerts.
* As soon as an alert is in state `FIRING` the alert is sent to Alertmanager. You should see the alert in its [web UI](http://localhost:9093).

{{% /details %}}

{{% details title="Task 3" %}}

Receivers `receiver-a` and `receiver-b` should be notified in this case.

Explanation:

* The label `team: team-b` set on the alert rule matches both receivers
* `continue: true` is set to true, therefore both receivers will be notified

```yaml
...
  routes:
    - receiver: 'receiver-a'
      match:
        team: 'team-a'
      continue: true
    - receiver: 'receiver-b'
      match_re:
        team: 'team-[a|b]'
...
```

{{% /details %}}
