---
title: "3.1 Monitor Alertmanager"
weight: 2
sectionnumber: 1
---

{{% alert title="Note" color="primary" %}}
This setup is only ok for our lab environment. In real life you must consider how to monitor your own monitoring infrastructure:
Having an Alertmanager instance as alertmanager AND as target in the same Prometheus is a bad idea!
{{% /alert %}}

### Task 1

This is repetition: Alertmanager also exposes metrics which can be scraped by Prometheus

* Configure the metric endpoint of Alertmanager in Prometheus

### Task 2

* Query one specific metric of Alertmanager

### Task 3

* Query all metrics which are exposed by Alertmanager

### Task 4

* How many minutes ago was the last successful configuration reload of Alertmanager?

## Solutions

{{% details title="Task 1" %}}

Configure a new job under `scrape_configs` in `prometheus.yml` and restart Prometheus (or reload when the `--web.enable-lifecycle` flag is enabled).
```
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'alertmanager'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9093']
```
{{% /details %}}


{{% details title="Task 2" %}}

To find out which metrics are available for one service you might query its metrics endpoint with curl, e.g. for Alertmanager:

```
curl localhost:9093/metrics
```

Then you get all metrics as follows (shortened) and you can pick whatever you're interested in:

```
Enable Alertmanager in `~/prometheus/prometheus-2.22.2.linux-amd64/prometheus.yml` and restart or reload (when the `--web.enable-lifecycle` flag is enabled) Prometheus.
# HELP alertmanager_alerts How many alerts by state.
# TYPE alertmanager_alerts gauge
alertmanager_alerts{state="active"} 0
alertmanager_alerts{state="suppressed"} 0
# HELP alertmanager_alerts_invalid_total The total number of received alerts that were invalid.
# TYPE alertmanager_alerts_invalid_total counter
alertmanager_alerts_invalid_total{version="v1"} 0
alertmanager_alerts_invalid_total{version="v2"} 0
# HELP alertmanager_alerts_received_total The total number of received alerts.
# TYPE alertmanager_alerts_received_total counter
alertmanager_alerts_received_total{status="firing",version="v1"} 0
alertmanager_alerts_received_total{status="firing",version="v2"} 0
alertmanager_alerts_received_total{status="resolved",version="v1"} 0
alertmanager_alerts_received_total{status="resolved",version="v2"} 0
(...)
```
{{% /details %}}

{{% details title="Task 3" %}}

Execute a query without a metric name, but with labels only:
```
{job="alertmanager"}
```
{{% /details %}}

{{% details title="Task 4" %}}

```
(time() - alertmanager_config_last_reload_success_timestamp_seconds) / 60
```
{{% /details %}}
